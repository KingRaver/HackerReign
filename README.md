# Hacker Reign

An advanced Next.js-powered AI chat application with local LLM integration via Ollama, featuring intelligent multi-model orchestration, domain-aware context detection, voice interaction with Whisper STT and Piper TTS, persistent conversation memory with semantic search, deep learning code generation, and advanced tool support.

## Features

### ğŸ¤– Multi-Model Strategy System
- **Intelligent Model Selection**: Automatically routes requests to optimal models based on task complexity
  - **3B Models** (Llama 3.2): Fast responses for simple tasks
  - **7B Models** (Qwen 2.5 Coder): Balanced for moderate complexity
  - **16B Models** (DeepSeek V2): Expert-level for complex analysis
- **Strategy Types**:
  - **Balanced** (Default): Complexity-based routing with resource awareness
  - **Speed**: Always fast models for quick responses
  - **Quality**: Always best models for maximum accuracy
  - **Cost**: Token-optimized for efficiency
  - **Adaptive**: ML-driven learning from historical performance
- **Multi-Model Workflows**:
  - **Chain Mode**: Draft â†’ Refine â†’ Review pipeline
  - **Ensemble**: Parallel voting for consensus
- **Resource Management**: Automatic adaptation to RAM, CPU, GPU, and battery constraints
- **Analytics**: SQLite-based performance tracking with continuous learning

### ğŸ¯ Domain Context System
- **Automatic Mode Detection**: Analyzes user input to select optimal interaction style
  - **Learning Mode** ğŸ“: Patient educator with examples and explanations
  - **Code Review Mode** ğŸ‘ï¸: Critical analyst focused on code quality
  - **Expert Mode** ğŸ§ : Deep technical discussions with trade-offs
  - **Auto-detect** ğŸ¤–: Pattern analysis to select best mode
- **Domain Knowledge Injection**: Specialized knowledge for your tech stack
  - **Python Backend**: Asyncio, FastAPI, concurrency patterns, best practices
  - **React Frontend**: Hooks, state management, performance optimization
  - **Next.js Fullstack**: App Router, Server Components, caching strategies
  - **Mixed**: Full-stack patterns, API design, authentication
- **Complexity Analysis**: AST-level code analysis with 0-100 scoring
  - Lines of code, cyclomatic complexity, async patterns
  - Technical keyword density, function/class counts
  - Multi-domain detection, conversation depth
- **Dynamic Parameters**: Temperature and token limits optimized per mode/complexity
- **Manual Override**: Force specific mode or model via UI controls

### ğŸ§  Memory & RAG System
- **Persistent Storage**: SQLite-based conversation history
- **Semantic Search**: Vector similarity search over past conversations
- **RAG Integration**: Retrieval-Augmented Generation with ChromaDB
- **Vector Embeddings**: Ollama nomic-embed-text for message embeddings
- **Strategy Analytics**: Performance tracking for ML-driven optimization
  - Decision logging with reasoning and confidence scores
  - Outcome tracking with quality metrics and user feedback
  - Automatic cleanup of old data (configurable retention)
- **Auto-Initialization**: Seamless setup with migration system

### ğŸ™ï¸ Voice Interaction System
- **Speech-to-Text**: Local Whisper transcription for accurate, private recognition
  - Push-to-talk (hold spacebar) or voice mode (auto-listen)
  - Automatic silence detection (3 seconds default)
  - 330MB `small` model for optimal speed/accuracy
- **Text-to-Speech**: High-quality Piper TTS synthesis
  - Server-side ONNX-based neural voice models
  - Multiple voice options with auto-download
  - Real-time frequency analysis for visualization
- **Unified Voice Flow**: State machine orchestration
  - States: idle â†’ listening â†’ processing â†’ thinking â†’ speaking â†’ auto-resume
  - Auto-resume 500ms after AI finishes speaking
  - Centralized state management with pub/sub pattern
- **Visual Feedback**:
  - **3D Particle Orb**: Three.js with 1000 particles, physics-based motion
  - **2D Voice Orb**: Canvas-based with state-aware colors (red=listening, cyan=speaking, teal=idle)
  - Audio-reactive animations with beat detection

### ğŸ§ª Deep Learning Code Generation
- **Neural Network Predictions**: TensorFlow.js-powered code completion
  - LSTM-based sequence-to-sequence architecture with embedding layers
  - Character-level tokenization for flexibility
  - Trained on code patterns and common completions
- **Context-Aware**: Uses conversation history for better predictions
- **Temperature Sampling**: Configurable diversity in predictions
- **Model Persistence**: Trained models saved to .data/dl-model.pt
- **Training Pipeline**: Batch processing with configurable epochs

### ğŸ› ï¸ Tool Support
- **Built-in Tools**: Weather queries, calculations (mathjs), safe code execution (vm2 sandbox)
- **Dynamic Tool Loading**: Automatic tool registration and execution
- **Loop Protection**: Max 5 iterations to prevent infinite loops
- **Error Handling**: Comprehensive error tracking with detailed logging

### âš¡ Performance & Reliability
- **Streaming Responses**: Real-time token streaming for responsive UX
- **Timeout Protection**: 30-second fetch timeouts prevent hanging
- **Comprehensive Logging**: Request lifecycle tracking with timestamps
- **Error Handling**: Detailed error messages with stack traces
- **Resource Monitoring**: Real-time RAM, CPU, GPU, battery tracking
- **Modern Stack**: Next.js 16, React 19, TypeScript, Tailwind CSS v4

## Prerequisites

### 1. Ollama
Install and run Ollama locally for LLM inference:

```bash
# Install Ollama (macOS)
brew install ollama

# Start Ollama service
ollama serve

# Pull models (choose based on your RAM)
ollama pull llama3.2:3b-instruct-q5_K_M      # Fast (4GB RAM)
ollama pull qwen2.5-coder:7b-instruct-q5_K_M  # Balanced (8GB RAM)
ollama pull deepseek-v2:16b-instruct-q4_K_M   # Expert (16GB RAM)

# Pull embedding model for RAG/semantic search
ollama pull nomic-embed-text
```

### 2. Node.js
Version 20 or higher recommended

### 3. Python, Whisper & Piper TTS (for voice features)

```bash
# Install Whisper (for speech-to-text)
pip3 install openai-whisper

# Download Whisper model (330MB - one-time setup)
whisper --model small --task transcribe /dev/null

# Install Piper TTS (for text-to-speech)
pip install piper-tts

# Verify Piper installation
python3 -m piper --version

# Piper voice models will auto-download to ~/.piper/models/ on first use
```

### 4. Modern Browser
- Chrome, Edge, or Safari for microphone access
- Microphone permission required for voice input

### 5. Database Storage
- ChromaDB (included in dependencies) for vector storage
- SQLite (via better-sqlite3) for conversation history
- No external database server required - fully local

## Getting Started

### 1. Install Dependencies

```bash
npm install
```

### 2. Configure Environment (Optional)

Create `.env.local` for custom settings:

```env
# Ollama API
OLLAMA_API_URL=http://localhost:11434
OLLAMA_EMBED_MODEL=nomic-embed-text

# Memory System
MEMORY_DB_PATH=./.data/hackerreign.db
CHROMA_DB_PATH=./.data/chroma

# Strategy System
STRATEGY_DEFAULT=balanced
STRATEGY_ENABLE_ANALYTICS=true

# Resource Limits
MAX_RAM_MB=16000
MAX_GPU_LAYERS=35
THERMAL_THRESHOLD=85

# Deep Learning
ENABLE_DL_PREDICTIONS=true

# Debug
DEBUG_CONTEXT=false
DEBUG_RAG=false
```

### 3. Run Development Server

```bash
npm run dev
```

### 4. Open Browser

Navigate to [http://localhost:3000](http://localhost:3000)

### 5. Start Using

**Text Chat:**
- Select mode: Auto-detect ğŸ¤–, Learning ğŸ“, Code Review ğŸ‘ï¸, or Expert ğŸ§ 
- Enable strategy system for intelligent model selection
- Type your message and watch the system adapt

**Voice Chat:**
- Click "Voice ON" or hold spacebar to speak
- System automatically resumes listening after responses
- Visual feedback shows current state (listening/thinking/speaking)

**Advanced Features:**
- Enable tools for weather, calculations, code execution
- View analytics to see model selection reasoning
- Manual override for specific models when needed

## System Architecture

### Multi-Model Strategy Flow

```
User Request
    â†“
[Context Building]
    â”œâ”€ Domain Detection (Python/React/Next.js)
    â”œâ”€ Complexity Analysis (0-100 score)
    â””â”€ Resource Monitoring (RAM/CPU/GPU)
    â†“
[Strategy Selection]
    â”œâ”€ Balanced: Complexity-based routing
    â”œâ”€ Speed: Always 3B model
    â”œâ”€ Quality: Always 16B model
    â”œâ”€ Cost: Token optimization
    â””â”€ Adaptive: ML-driven learning
    â†“
[Resource Constraints]
    â”œâ”€ RAM limits â†’ downgrade model
    â”œâ”€ CPU usage â†’ reduce tokens
    â”œâ”€ Battery mode â†’ fast model
    â””â”€ Thermal â†’ throttle generation
    â†“
[Model Selection]
    â”œâ”€ 3B: Simple tasks (score < 30)
    â”œâ”€ 7B: Moderate tasks (score 30-70)
    â””â”€ 16B: Complex tasks (score > 70)
    â†“
[Optional Workflows]
    â”œâ”€ Chain: Draft â†’ Refine â†’ Review
    â””â”€ Ensemble: Parallel voting
    â†“
[LLM Inference via Ollama]
    â†“
[Analytics Logging]
    â”œâ”€ Decision: model, reasoning, confidence
    â””â”€ Outcome: quality, time, tokens, feedback
```

### Voice Interaction Flow

```
User speaks (hold space or voice ON)
    â†“
[Browser MediaRecorder] â†’ captures audio
    â†“
[POST /api/stt] â†’ Whisper transcription
    â†“
[Text appears in chat]
    â†“
[Strategy System] â†’ selects model
    â†“
[LLM generates response]
    â†“
[POST /api/piper-tts] â†’ speech synthesis
    â†“
[Audio playback with visualization]
    â†“
[Auto-resume listening after 500ms]
```

### Memory & RAG Flow

```
User message
    â†“
[RAG Search] â†’ find similar past conversations
    â”œâ”€ Generate embedding (Ollama)
    â”œâ”€ Vector search (ChromaDB)
    â””â”€ Retrieve top K similar messages
    â†“
[Context Building] â†’ inject retrieved context
    â†“
[Enhanced System Prompt]
    â”œâ”€ Domain knowledge
    â”œâ”€ Mode-specific guidance
    â””â”€ Relevant past conversations
    â†“
[LLM with enriched context]
    â†“
[Save response to memory]
    â”œâ”€ SQLite storage
    â””â”€ Vector embedding for future RAG
```

## Project Structure

```
hackerreign/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ llm/route.ts              # Main LLM endpoint with strategy integration
â”‚   â”‚   â”œâ”€â”€ stt/route.ts              # Whisper speech-to-text
â”‚   â”‚   â”œâ”€â”€ piper-tts/route.ts        # Piper text-to-speech
â”‚   â”‚   â””â”€â”€ dl-codegen/               # Deep learning code generation
â”‚   â”‚       â”œâ”€â”€ predict/route.ts      # Neural network predictions
â”‚   â”‚       â””â”€â”€ train/route.ts        # Model training endpoint
â”‚   â”‚
â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”œâ”€â”€ strategy/                 # Multi-model orchestration system
â”‚   â”‚   â”‚   â”œâ”€â”€ manager.ts            # Main orchestrator
â”‚   â”‚   â”‚   â”œâ”€â”€ types.ts              # TypeScript interfaces
â”‚   â”‚   â”‚   â”œâ”€â”€ baseStrategy.ts       # Abstract base class
â”‚   â”‚   â”‚   â”œâ”€â”€ context.ts            # Context builder
â”‚   â”‚   â”‚   â”œâ”€â”€ implementations/      # Strategy implementations
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ complexityStrategy.ts  # Balanced (default)
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ speedStrategy.ts       # Always fast
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ qualityStrategy.ts     # Always best
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ costStrategy.ts        # Token optimization
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ adaptiveStrategy.ts    # ML-driven
â”‚   â”‚   â”‚   â”œâ”€â”€ workflows/            # Multi-model workflows
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ chain.ts          # Sequential chaining
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ensemble.ts       # Parallel voting
â”‚   â”‚   â”‚   â”œâ”€â”€ resources/            # Resource management
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ monitor.ts        # System monitoring
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ constraints.ts    # Resource constraints
â”‚   â”‚   â”‚   â”œâ”€â”€ analytics/            # Performance tracking
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ tracker.ts        # SQLite analytics
â”‚   â”‚   â”‚   â””â”€â”€ orchestrator.ts       # Workflow execution
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ domain/                   # Context detection system
â”‚   â”‚   â”‚   â”œâ”€â”€ contextDetector.ts    # Mode/domain/complexity detection
â”‚   â”‚   â”‚   â”œâ”€â”€ domainKnowledge.ts    # Tech stack knowledge bases
â”‚   â”‚   â”‚   â”œâ”€â”€ modeDefinitions.ts    # Learning/Review/Expert modes
â”‚   â”‚   â”‚   â””â”€â”€ contextBuilder.ts     # System prompt generation
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ memory/                   # Persistent storage & RAG
â”‚   â”‚   â”‚   â”œâ”€â”€ index.ts              # MemoryManager API
â”‚   â”‚   â”‚   â”œâ”€â”€ schemas.ts            # TypeScript types
â”‚   â”‚   â”‚   â”œâ”€â”€ storage/              # SQLite storage layer
â”‚   â”‚   â”‚   â”œâ”€â”€ rag/                  # Vector embeddings & search
â”‚   â”‚   â”‚   â””â”€â”€ migrations/           # Database schema migrations
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ voice/                    # Voice interaction system
â”‚   â”‚   â”‚   â”œâ”€â”€ useVoiceInput.ts      # STT React hook
â”‚   â”‚   â”‚   â”œâ”€â”€ useVoiceOutput.ts     # TTS React hook
â”‚   â”‚   â”‚   â”œâ”€â”€ useVoiceFlow.ts       # Unified orchestration
â”‚   â”‚   â”‚   â”œâ”€â”€ voiceStateManager.ts  # Centralized state
â”‚   â”‚   â”‚   â””â”€â”€ audioAnalyzer.ts      # FFT analysis
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ dl-codegen/               # Deep learning code generation
â”‚   â”‚   â”‚   â”œâ”€â”€ index.ts              # Public API exports
â”‚   â”‚   â”‚   â”œâ”€â”€ types.ts              # TypeScript type definitions
â”‚   â”‚   â”‚   â”œâ”€â”€ preprocess.ts         # Tokenization and sequence prep
â”‚   â”‚   â”‚   â”œâ”€â”€ model.ts              # LSTM neural network architecture
â”‚   â”‚   â”‚   â””â”€â”€ train.ts              # Training loop and persistence
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ tools/                    # LLM tool support
â”‚   â”‚       â”œâ”€â”€ definitions.ts        # Tool schemas
â”‚   â”‚       â”œâ”€â”€ executor.ts           # Tool execution
â”‚   â”‚       â””â”€â”€ handlers/             # Individual tool handlers
â”‚   â”‚
â”‚   â””â”€â”€ page.tsx                      # Main chat interface
â”‚
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ Chat.tsx                      # Main chat component
â”‚   â”œâ”€â”€ VoiceOrb.tsx                  # 2D canvas audio visualization
â”‚   â””â”€â”€ ParticleOrb.tsx               # 3D Three.js particle system
â”‚
â”œâ”€â”€ .data/                            # Runtime data storage (not in git)
â”‚   â”œâ”€â”€ chroma/                       # ChromaDB vector database
â”‚   â”œâ”€â”€ chroma.log                    # ChromaDB logs
â”‚   â”œâ”€â”€ dl-model.pt                   # Trained deep learning model
â”‚   â”œâ”€â”€ hackerreign.db                # SQLite conversation history
â”‚   â”œâ”€â”€ hackerreign.db-shm            # SQLite shared memory
â”‚   â””â”€â”€ hackerreign.db-wal            # SQLite write-ahead log
â”‚
â”œâ”€â”€ data/                             # Application data
â”‚   â””â”€â”€ strategy_analytics.db         # Strategy performance analytics
â”‚
â””â”€â”€ public/
    â”œâ”€â”€ codesnippets.json             # Code snippet training data
    â”œâ”€â”€ favicon.ico                   # Site favicon
    â””â”€â”€ *.svg                         # Static assets
```

## API Endpoints

### LLM & Strategy
- **POST /api/llm**: Main chat endpoint with strategy system integration
  - Accepts: `messages`, `strategyEnabled`, `selectedStrategy`, `filePath`, `manualModeOverride`
  - Returns: Streaming response with auto-selected model info

### Voice
- **POST /api/stt**: Whisper speech-to-text transcription
- **POST /api/piper-tts**: Piper text-to-speech synthesis
- **GET /api/piper-tts/voices**: List available voice models

### Deep Learning
- **POST /api/dl-codegen/predict**: Neural network code predictions
- **POST /api/dl-codegen/train**: Trigger model training

## Configuration

### Strategy System

```typescript
// Enable in Chat.tsx
const [strategyEnabled, setStrategyEnabled] = useState(true);
const [selectedStrategy, setSelectedStrategy] = useState('balanced');

// Strategies: 'balanced', 'speed', 'quality', 'cost', 'adaptive'
```

### Memory System

```typescript
import { getMemoryManager } from '@/lib/memory';

const memory = getMemoryManager();
await memory.initialize();

// Save messages
await memory.saveMessage(conversationId, 'user', content);

// Semantic search
const similar = await memory.retrieveSimilarMessages(query, topK=5);

// Get analytics
const stats = await memory.getStats();
```

### Domain Context

```typescript
import { buildContextForLLMCall } from '@/lib/domain/contextBuilder';

const context = await buildContextForLLMCall(
  userMessage,
  filePath,              // Optional: for file type detection
  manualModeOverride     // Optional: 'learning' | 'code-review' | 'expert'
);

// Use context.systemPrompt, context.temperature, context.maxTokens
```

## Troubleshooting

### Strategy System Issues

**Models keep getting downgraded:**
- Check available RAM: System may be resource-constrained
- Adjust constraints in `app/lib/strategy/resources/constraints.ts`
- Increase `MAX_RAM_MB` in environment variables

**Adaptive strategy not learning:**
- Need at least 20-30 decisions for meaningful patterns
- Check analytics database: `data/strategy_analytics.db`
- Ensure outcomes are being logged after responses

### LLM Issues

**Request timeouts:**
1. Check Ollama is running: `ollama list`
2. Verify service: `curl http://localhost:11434/v1/models`
3. Check model size vs available RAM
4. Review strategy logs for auto-downgrade reasoning

**Tool execution errors:**
1. Verify dependencies: `npm list mathjs vm2`
2. Check console for `[Tool Executor]` messages
3. Review tool handler mapping in `app/lib/tools/executor.ts`

### Memory System Issues

**RAG not finding relevant context:**
1. Ensure embedding model is pulled: `ollama pull nomic-embed-text`
2. Check ChromaDB path exists: `mkdir -p .data/chroma`
3. Verify messages are being embedded (check logs)
4. Adjust `RAG_SIMILARITY_THRESHOLD` (default 0.3)

**Database locked errors:**
1. Increase timeout in tracker.ts
2. Enable WAL mode: `this.db.pragma('journal_mode = WAL')`
3. Check for concurrent writes from parallel requests

### Voice System Issues

**Whisper STT not working:**
1. Install: `pip3 install openai-whisper`
2. Download model: `whisper --model small --task transcribe /dev/null`
3. Check PATH or set `WHISPER_PATH` environment variable
4. Review console for `[STT]` error messages

**Piper TTS not working:**
1. Install: `pip install piper-tts`
2. Verify: `python3 -m piper --version`
3. Voice models auto-download to `~/.piper/models/`
4. Check console for `[Piper]` errors

**Microphone not capturing:**
1. Grant browser microphone permission
2. Test system microphone in other apps
3. Check browser compatibility (Chrome/Edge/Safari recommended)
4. Review console for `[VoiceInput]` messages

### Deep Learning Issues

**Predictions not appearing:**
1. Check `ENABLE_DL_PREDICTIONS` is not false
2. Ensure model file exists at `.data/dl-model.pt`
3. Train model first using POST /api/dl-codegen/train
4. Review console for `[DL]` error messages

## Development Scripts

```bash
npm run dev         # Start development server
npm run build       # Build for production
npm start           # Start production server
npm run lint        # Run ESLint
npm run type-check  # Check TypeScript types
```

## Documentation

- **Project Structure**: [STRUCTURE.md](STRUCTURE.md) - Complete project organization
- **LLM Models Guide**: [MODELS.md](MODELS.md) - Model selection and configuration
- **Future Roadmap**: [FUTURE.md](FUTURE.md) - Planned features and enhancements
- **Memory & RAG**: [app/lib/memory/README.md](app/lib/memory/README.md)
- **Memory Integration**: [app/lib/memory/INTEGRATION_GUIDE.md](app/lib/memory/INTEGRATION_GUIDE.md)
- **Memory File Manifest**: [app/lib/memory/FILE_MANIFEST.md](app/lib/memory/FILE_MANIFEST.md)
- **Voice System**: [app/lib/voice/README.md](app/lib/voice/README.md)
- **Voice Quick Test**: [app/lib/voice/QUICK_TEST.md](app/lib/voice/QUICK_TEST.md)
- **Voice Optimization**: [app/lib/voice/VOICE_OPTIMIZATION.md](app/lib/voice/VOICE_OPTIMIZATION.md)

## Recent Updates

### v2.0.0 - Multi-Model Strategy System
- **Intelligent Orchestration**: Automatic model selection based on complexity
- **Resource Management**: RAM/CPU/GPU/battery-aware constraints
- **ML-Driven Learning**: Adaptive strategy learns from historical performance
- **Multi-Model Workflows**: Chain and ensemble execution modes
- **Analytics Dashboard**: SQLite-based performance tracking
- **5 Strategy Types**: Balanced, Speed, Quality, Cost, Adaptive

### v1.3.0 - Domain Context System
- **Context Detection**: Automatic mode and domain detection
- **Mode System**: Learning, Code Review, Expert with specialized prompts
- **Domain Knowledge**: Python, React, Next.js knowledge injection
- **Complexity Analysis**: AST-level code analysis with 0-100 scoring
- **UI Integration**: Mode selector with manual override

### v1.2.0 - Voice Interaction System
- **Whisper STT**: Local speech-to-text transcription
- **Piper TTS**: High-quality speech synthesis
- **Unified Voice Flow**: Complete orchestration with auto-resume
- **Visual Feedback**: 3D particle system and 2D orb
- **State Management**: Centralized voiceStateManager

### v1.1.0 - Memory & RAG System
- **SQLite Storage**: Persistent conversation history
- **Vector Embeddings**: Semantic search with Ollama
- **ChromaDB Integration**: Efficient similarity search
- **Analytics**: Search performance tracking

## Learn More

- [Next.js Documentation](https://nextjs.org/docs)
- [Ollama Documentation](https://ollama.ai/docs)
- [OpenAI Function Calling](https://platform.openai.com/docs/guides/function-calling)
- [Whisper Documentation](https://github.com/openai/whisper)
- [Piper TTS Documentation](https://github.com/rhasspy/piper)
- [ChromaDB Documentation](https://docs.trychroma.com/)
- [TensorFlow.js Documentation](https://www.tensorflow.org/js)

## License

Â©2026 | Vivid Visions | HackerReignâ„¢
